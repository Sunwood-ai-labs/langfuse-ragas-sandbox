# Ragasを使用したRAGシステムの評価

このディレクトリでは、Ragasライブラリを使用してRAGシステムの性能を評価する実装を提供します。

## 📊 評価指標

以下の標準的なRagas評価指標を使用します：

1. **Faithfulness（忠実性）**
   - 回答が与えられたコンテキストに忠実であるかを評価
   - 事実の誤認や誤った情報の混入がないかをチェック

2. **AnswerRelevancy（回答の関連性）**
   - 回答が質問に適切に対応しているかを評価
   - 質問の意図と回答の整合性を確認

3. **ContextRelevancy（文脈の関連性）**
   - 選択されたコンテキストが質問に関連しているかを評価
   - 不必要な情報の混入を検出

4. **AspectCritique（多面的評価）**
   - 明確さ（clarity）
   - 完全性（completeness）
   - 正確性（accuracy）

## 🚀 実行方法

```bash
python evaluate_rag.py
```

## 💡 評価プロセス

1. データセットの準備
   - マーダーミステリーの事例からテストケースを生成
   - 質問、コンテキスト、正解の組み合わせを作成

2. モデルごとの評価
   - GPT-4による評価
   - GPT-4 Turbo Previewによる評価

3. 結果の記録
   - 各評価指標のスコアをLangfuseに記録
   - モデル名を含めた形式で結果を保存
   - スコアの時系列での変化を追跡

## 📈 Langfuseでの確認方法

1. Langfuseダッシュボードにアクセス
2. Metricsタブで各評価指標のスコアを確認
3. モデル間での比較分析が可能
4. 時系列でのパフォーマンス推移を確認

## 🔧 カスタマイズ

- 評価指標の重みづけ調整が可能
- 新しい評価指標の追加も可能
- テストケースの追加や修正が可能

## ⚠️ 注意事項

- 評価には大量のAPIコールが必要となるため、コストに注意
- 評価結果は相対的な比較として使用することを推奨
- 定期的な評価の実行で、パフォーマンスの変化を監視
